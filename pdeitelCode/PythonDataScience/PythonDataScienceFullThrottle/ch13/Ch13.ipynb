{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy; 2024 by Pearson Education, Inc. All Rights Reserved. The content in this notebook is based on the book [**Python for Programmers**](https://amzn.to/2VvdnxE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- CSS settings for this notbook -->\n",
       "<style>\n",
       "    h1 {color:#BB0000}\n",
       "    h2 {color:purple}\n",
       "    h3 {color:#0099ff}\n",
       "    hr {    \n",
       "        border: 0;\n",
       "        height: 3px;\n",
       "        background: #333;\n",
       "        background-image: linear-gradient(to right, #ccc, black, #ccc);\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!-- CSS settings for this notbook -->\n",
    "<style>\n",
    "    h1 {color:#BB0000}\n",
    "    h2 {color:purple}\n",
    "    h3 {color:#0099ff}\n",
    "    hr {    \n",
    "        border: 0;\n",
    "        height: 3px;\n",
    "        background: #333;\n",
    "        background-image: linear-gradient(to right, #ccc, black, #ccc);\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 13. IBM Watson and Cognitive Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "* Develop a **traveler’s companion language translator app**, using Python to weave together a **mashup** of the **Watson Speech to Text**, **Language Translator** and **Text to Speech** services\n",
    "* **Cognitive computing** and how you can incorporate it into your applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.1 Introduction: IBM Watson and Cognitive Computing (1 of 2)\n",
    "* Cloud-based **cognitive-computing** platform employed across a wide range of real-world applications\n",
    "    * Simulate the **pattern-recognition** and **decision-making** capabilities of the human brain \n",
    "    * **“learns”** as it **consumes more data** [\\[4\\]](http://whatis.techtarget.com/definition/cognitive-computing), [\\[5\\]](https://en.wikipedia.org/wiki/Cognitive_computing), [\\[6\\]](https://www.forbes.com/sites/bernardmarr/2016/03/23/what-everyone-should-know-about-cognitive-computing)\n",
    "* **IBM artificial-intelligence accomplishments** include beating the two best human **Jeopardy!** players [\\[1\\]](https://www.techrepublic.com/article/ibm-watson-the-inside-story-of-how-the-jeopardy-winning-supercomputer-was-born-and-what-it-wants-to-do-next/), [\\[2\\]](https://en.wikipedia.org/wiki/Watson_(computer))\n",
    "    * IBM researchers trained Watson using **machine-learning** and **reinforcement-learning** techniques [\\[3\\]](https://www.aaai.org/Magazine/Watson/watson.php) \n",
    "* [View our table showing many ways in which organizations are using Watson](https://learning.oreilly.com/library/view/Python+for+Programmers,+First+Edition/9780135231364/ch13.xhtml#ch13lev1sec1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.1 Introduction: IBM Watson and Cognitive Computing (2 of 2)\n",
    "* **Watson demos** allow you to experiment with various **web services**\n",
    "    * natural language translation\n",
    "    * speech-to-text\n",
    "    * text-to-speech\n",
    "    * natural language understanding\n",
    "    * chatbots\n",
    "    * analyzing text for tone\n",
    "    * visual object recognition in images and video\n",
    "* We'll develop a **traveler’s companion translation app** by quickly and conveniently **mashing up several Watson services**\n",
    "    * Enables **English-only** and **Spanish-only speakers** to communicate with one another verbally, despite the language barrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.2 IBM Cloud Account and Cloud Console\n",
    "* Provides access **Watson’s services** (both free and paid)\n",
    "* **Free Lite tier** make it easy to **experiment with Watson**\n",
    "* Lite tier **limits your use** for experimentation\n",
    "* **Paid tiers** for **commercial applications**\n",
    "* [**Sign up**](https://cloud.ibm.com/docs/services/watson?topic=watson-about#about)\n",
    "* [**Watson dashboard**](https://cloud.ibm.com/developer/watson/dashboard) gives you access to your Watson services \n",
    "* [See the sign-up process in my **Python Fundamentals** videos](https://learning.oreilly.com/videos/python-fundamentals/9780135917411/9780135917411-PFLL_Lesson13_02) \n",
    "* [Read about the sign-up process in **Python for Programmers**](https://learning.oreilly.com/library/view/python-for-programmers/9780135231364/ch13.xhtml#ch13lev1sec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.5 Watson Developer Cloud Python SDK (1 of 2)\n",
    "* IBM provides the **Watson Developer Cloud Python SDK** \n",
    "* [**Python Fundamentals**](https://learning.oreilly.com/videos/python-fundamentals/9780135917411/9780135917411-PFLL_Lesson13_05), [**Python for Programmers**](https://learning.oreilly.com/library/view/python-for-programmers/9780135231364/ch13.xhtml#ch13lev1sec5)\n",
    "* **`ibm_watson` module**: Classes for **interacting with Watson services**\n",
    "* [**Install the SDK**](https://github.com/watson-developer-cloud/python-sdk/) \n",
    "```\n",
    "pip install --upgrade ibm-watson\n",
    "```\n",
    "> **Windows users** might need to [install Microsoft’s C++ build tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/), then install the watson-developer-cloud module)\n",
    "* On GitHub, [**IBM provides sample code**](https://github.com/watson-developer-cloud/python-sdk/tree/master/examples) \n",
    "    * Demonstrates **accessing Watson services** using the SDK’s classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules We’ll Need for Audio Recording and Playback (2 of 2)\n",
    "```\n",
    "pip install sounddevice  \n",
    "pip install simpleaudio \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.6 Case Study: Traveler’s Companion Translation App\n",
    "* Use three **IBM Watson services** to quickly **implement** a **traveler’s companion translation app**\n",
    "    * Enables people who **speak only English** and **speak only Spanish to converse**\n",
    "* Combining services like this is known as creating a **mashup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.6.1 Before You Run the App \n",
    "* Requires an **IBM Cloud account** and **credentials** for each service\n",
    "* **Insert your credentials in our `keys.py` file** that we import into the example\n",
    "* For steps to **signup** and **get your credentials**, see my [**Python Fundamentals LiveLessons** (four videos starting with this one)](https://learning.oreilly.com/videos/python-fundamentals/9780135917411/9780135917411-PFLL_Lesson13_07) or [**Python for Programmers, Section 13.6.1**](https://learning.oreilly.com/library/view/python-for-programmers/9780135231364/ch13.xhtml#ch13lev2sec1)\n",
    "* **View your credentials**: Click [**service instance's name** in your list of services](https://cloud.ibm.com/resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.6.2 Test-Driving the App\n",
    "* **Lecture note: Play video of this app in action**\n",
    "    * Due to my live training setup, I can't run this app live as you'd **hear only half the conversation**\n",
    "\n",
    "<!--\n",
    "%%HTML\n",
    "<video width=\"100%\" controls>\n",
    "  <source src=\"./SimpleLanguageTranslator.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.6.3 `SimpleLanguageTranslator.py` Script Walkthrough\n",
    "* The script is divided into **10 steps**\n",
    "* **Processing the English question** \n",
    "    * **Step 1:** Prompt for then **record English speech** into an audio file  \n",
    "    * **Step 2:** **Transcribe** the English speech to **English text**  \n",
    "    * **Step 3:** **Translate** the English text into Spanish text  \n",
    "    * **Step 4:** **Synthesize** the Spanish text into **Spanish speech** and save it into an audio file  \n",
    "    * **Step 5:** **Play** the Spanish **audio** file  \n",
    "* **Processing the Spanish response**  \n",
    "    * **Step 6:** Prompt for then **record Spanish speech** into an audio file  \n",
    "    * **Step 7:** **Transcribe** the Spanish speech to **Spanish text**  \n",
    "    * **Step 8:** **Translate** the Spanish text into English text  \n",
    "    * **Step 9:** **Synthesize** the English text into **English speech** and save it into an audio file  \n",
    "    * **Step 10:** **Play** the English **audio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Watson SDK Classes from the `ibm_watson` Module \n",
    "```python\n",
    "# SimpleLanguageTranslator.py\n",
    "\"\"\"Use IBM Watson Speech to Text, Language Translator and Text to Speech\n",
    "   APIs to enable English and Spanish speakers to communicate.\"\"\"\n",
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_watson import LanguageTranslatorV3\n",
    "from ibm_watson import TextToSpeechV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator # *** NEW\n",
    "```\n",
    "\n",
    "* **`SpeechToTextV1`** \n",
    "    * Passes an **audio file** to the **Watson Speech to Text service** \n",
    "    * Receives a **JSON document** containing the **text transcription**\n",
    "* **`LanguageTranslatorV3`** \n",
    "    * Passes **text** to the **Watson Language Translator service** \n",
    "    * Receives a **JSON document** containing the **translated text** \n",
    "* **`TextToSpeechV1`** \n",
    "    * Passes **text** to the **Watson Text to Speech service** \n",
    "    * Receives **audio** of the text **spoken in a specified language**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Imported Modules\n",
    "```python\n",
    "import keys  # contains your API keys for accessing Watson services\n",
    "import wave  \n",
    "import simpleaudio as sa\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "```\n",
    "\n",
    "* **`sounddevice`** for **recording audio** \n",
    "* **`simpleaudio`** to **load and play audio files**\n",
    "* **`wave`** to save **WAV (Waveform Audio File Format) files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program: Function `run_translator` (1 of 6)\n",
    "* **`run_translator`** invoked when **`SimpleLanguageTranslator.py` executed as a script**\n",
    "\n",
    "```python\n",
    "def run_translator():\n",
    "    \"\"\"Calls the functions that interact with Watson services.\"\"\"\n",
    "    # Step 1: Prompt for then record English speech into an audio file \n",
    "    input('Press Enter then ask your question in English')\n",
    "    record_audio('english.wav')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program: Function `run_translator` (2 of 6)\n",
    "* **Step 2**: Call **`speech_to_text`**\n",
    "    * **Speech to Text service** transcribes text using **predefined models**\n",
    "    * They now have general multimedia models and models optimized for telephone audio \n",
    "\n",
    "```python\n",
    "    # Step 2: Transcribe the English speech to English text\n",
    "    english = speech_to_text(\n",
    "        file_name='english.wav', model_id='en-US_Multimedia')\n",
    "    print('English:', english)  # display transcription\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program: Function `run_translator` (3 of 6)\n",
    "* **Step 3**: Call **`translate`**\n",
    "    * **Predefined model `'en-es'`** translates from **English (`en`) to Spanish (`es`)**\n",
    "\n",
    "```python\n",
    "    # Step 3: Translate the English text into Spanish text\n",
    "    spanish = translate(text_to_translate=english, model='en-es')\n",
    "    print('Spanish:', spanish)  # display translated text\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program: Function `run_translator` (4 of 6)\n",
    "* **Voice `'es-US_SofiaV3Voice'`** is for Spanish as spoken in the U.S.\n",
    "\n",
    "```python    \n",
    "    # Step 4: Synthesize the Spanish text into Spanish speech \n",
    "    text_to_speech(text_to_speak=spanish, \n",
    "        voice_to_use='es-US_SofiaV3Voice',\n",
    "        file_name='spanish.wav')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program: Function `run_translator` (5 of 6)\n",
    "* **Step 5**: Call **`play_audio`** to play the file **`'spanish.wav'`**.\n",
    "\n",
    "```python\n",
    "    # Step 5: Play the Spanish audio file\n",
    "    play_audio(file_name='spanish.wav')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program: Function `run_translator` (6 of 6)\n",
    "* **Steps 6–10** repeat previous steps for **Spanish speech to English speech**: \n",
    "    * **Step 6** **records** the Spanish audio\n",
    "    * **Step 7** **transcribes** the **Spanish audio** to Spanish text using predefined model **`'es-ES_Multimedia'`**\n",
    "    * **Step 8** **translates** the **Spanish text** to English text using predefined model **`'es-en'`** (Spanish-to-English)\n",
    "    * **Step 9** **creates** the **English audio** using **`'en-US_AllisonV3Voice'`**\n",
    "    * **Step 10** **plays** the English **audio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # Step 6: Prompt for then record Spanish speech into an audio file\n",
    "    input('Press Enter then speak the Spanish answer')\n",
    "    record_audio('spanishresponse.wav')\n",
    "\n",
    "    # Step 7: Transcribe the Spanish speech to Spanish text\n",
    "    spanish = speech_to_text(\n",
    "        file_name='spanishresponse.wav', \n",
    "        model_id='es-ES_Multimedia')\n",
    "    print('Spanish response:', spanish)\n",
    "\n",
    "    # Step 8: Translate the Spanish text to English text\n",
    "    english = translate(text_to_translate=spanish, model='es-en')\n",
    "    print('English response:', english)\n",
    "\n",
    "    # Step 9: Synthesize the English text to English speech\n",
    "    text_to_speech(text_to_speak=english,\n",
    "        voice_to_use='en-US_AllisonV3Voice',\n",
    "        file_name='englishresponse.wav')\n",
    "\n",
    "    # Step 10: Play the English audio\n",
    "    play_audio(file_name='englishresponse.wav')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `speech_to_text` (1 of 4) Accesses **Watson’s Speech to Text Service**\n",
    "```python\n",
    "def speech_to_text(file_name, model_id):\n",
    "    \"\"\"Use Watson Speech to Text to convert audio file to text.\"\"\"\n",
    "    authenticator = IAMAuthenticator(keys.speech_to_text_key) \n",
    "    stt = SpeechToTextV1(authenticator=authenticator)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `speech_to_text` (2 of 4) Accesses **Watson’s Speech to Text Service**\n",
    "```python\n",
    "    # open the audio file \n",
    "    with open(file_name, 'rb') as audio_file:\n",
    "        # pass the file to Watson for transcription\n",
    "        result = stt.recognize(audio=audio_file, \n",
    "            content_type='audio/wav', model=model_id).get_result()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `speech_to_text` (3 of 4)\n",
    "* **`recognize`** returns a **`DetailedResponse` object** \n",
    "    * Depending on arguments to **`recognize`**, may contain intermediate and final results\n",
    "    * Useful when transcribing **live audio**, such as a newscast\n",
    "    * [Method `recognize`’s arguments and JSON response details](https://www.ibm.com/watson/developercloud/speech-to-text/api/v1/python.html?python#recognize-sessionless).\n",
    "* **`getResult` method** returns **JSON** containing **`transcript`**:\n",
    "```json\n",
    "{\n",
    "  \"result_index\": 0,\n",
    "  \"results\": [\n",
    "    {\n",
    "      \"final\": true,\n",
    "      \"alternatives\": [\n",
    "        {\n",
    "          \"transcript\": \"where is the nearest bathroom \",\n",
    "          \"confidence\": 0.96\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `speech_to_text` (4 of 4) Accesses **Watson’s Speech to Text Service**\n",
    "```python\n",
    "    # Get the 'results' list. This may contain intermediate and final\n",
    "    # results, depending on method recognize's arguments. We asked \n",
    "    # for only final results, so this list contains one element.\n",
    "    results_list = result['results'] \n",
    "\n",
    "    # Get the final speech recognition result--the list's only element.\n",
    "    speech_recognition_result  = results_list[0]\n",
    "\n",
    "    # Get the 'alternatives' list. This may contain multiple alternative\n",
    "    # transcriptions, depending on method recognize's arguments. We did\n",
    "    # not ask for alternatives, so this list contains one element.\n",
    "    alternatives_list = speech_recognition_result['alternatives']\n",
    "\n",
    "    # Get the only alternative transcription from alternatives_list.\n",
    "    first_alternative = alternatives_list[0]\n",
    "\n",
    "    # Get the 'transcript' key's value, which contains the audio's \n",
    "    # text transcription.\n",
    "    transcript = first_alternative['transcript']\n",
    "\n",
    "    return transcript  # return the audio's text transcription\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `translate` (1 of 4) Accesses the **Watson Language Translator Service**\n",
    "* Creates a **`LanguageTranslatorV3`**, passing **service version (`'2018-05-31'`)** and **API Key**\n",
    "    * **Version string (`'2018-05-31'`)** changes only if IBM makes **breaking API changes** \n",
    "    * Service still responds using **API version you specify**\n",
    "    * [More details](https://cloud.ibm.com/apidocs/language-translator?code=python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `translate` (2 of 4)\n",
    "```python\n",
    "def translate(text_to_translate, model):\n",
    "    \"\"\"Use Watson Language Translator to translate English to Spanish \n",
    "       (en-es) or Spanish to English (es-en) as specified by model.\"\"\"\n",
    "    # create Watson Translator client\n",
    "    authenticator = IAMAuthenticator(keys.translate_key) \n",
    "    language_translator = LanguageTranslatorV3(version='2018-05-31',\n",
    "        authenticator=authenticator)\n",
    "\n",
    "    # perform the translation\n",
    "    translated_text = language_translator.translate(\n",
    "        text=text_to_translate, model_id=model).get_result()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `translate` Returns a **`DetailedResponse`** (4 of 4)\n",
    "* **`getResult` method** returns **JSON** containing **translation** \"donde es el baño más cercano\": \n",
    "```json\n",
    "{\n",
    "  \"translations\": [\n",
    "    {\n",
    "      \"translation\": \"donde es el ba\\u00f1o m\\u00e1s cercano \"\n",
    "    }\n",
    "  ],\n",
    "  \"word_count\": 5,\n",
    "  \"character_count\": 30\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `translate` (3 of 4)\n",
    "```python\n",
    "    # get 'translations' list. If method translate's text argument has \n",
    "    # multiple strings, the list will have multiple entries. We passed\n",
    "    # one string, so the list contains only one element.\n",
    "    translations_list = translated_text['translations']\n",
    "    \n",
    "    # get translations_list's only element\n",
    "    first_translation = translations_list[0]\n",
    "\n",
    "    # get 'translation' key's value, which is the translated text\n",
    "    translation = first_translation['translation']\n",
    "\n",
    "    return translation  # return the translated string\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `text_to_speech` Accesses **Watson Text to Speech Service** (1 of 2)\n",
    "* Creates a **`TextToSpeechV1` object** named `tts` (short for text-to-speech), passing the **API key**. \n",
    "* **`with` statement** opens audio file for writing.  \n",
    "\n",
    "```python\n",
    "def text_to_speech(text_to_speak, voice_to_use, file_name):\n",
    "    \"\"\"Use Watson Text to Speech to convert text to specified voice\n",
    "       and save to a WAV file.\"\"\"\n",
    "    # create Text to Speech client\n",
    "    authenticator = IAMAuthenticator(keys.text_to_speech_key)\n",
    "    tts = TextToSpeechV1(authenticator=authenticator)\n",
    "\n",
    "    # open file and write the synthesized audio content into the file\n",
    "    with open(file_name, 'wb') as audio_file:\n",
    "        audio_file.write(tts.synthesize(text_to_speak, \n",
    "            accept='audio/wav', voice=voice_to_use).get_result().content)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `text_to_speech` (3 of 3)\n",
    "* **`synthesize`** method's **`voice`** argument is a **predefined voice** \n",
    "    * **`'en-US_AllisonVoice'`** or **`'es-US_SofiaVoice'`** in this example\n",
    "    *  [**Voices for various languages**](https://cloud.ibm.com/apidocs/text-to-speech?code=python)\n",
    "* **`get_result`** returns a **`DetailedResponse`** containing **spoken audio as bytes**\n",
    "    * **`content` attribute** gets the **audio bytes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions `record_audio` and `play_audio`\n",
    "* Won't discuss audio functions to save time\n",
    "* For details on them, see my **Python Fundamentals LiveLessons videos**\n",
    "    * [Function record_audio](https://learning.oreilly.com/videos/python-fundamentals/9780135917411/9780135917411-PFLL_Lesson13_19) \n",
    "    * [Function play_audio](https://learning.oreilly.com/videos/python-fundamentals/9780135917411/9780135917411-PFLL_Lesson13_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `record_audio` (2 of 4)\n",
    "```python \n",
    "def record_audio(file_name):\n",
    "    \"\"\"Use pyaudio to record 5 seconds of audio to a WAV file.\"\"\"\n",
    "    FRAME_RATE = 44100  # number of frames per second\n",
    "    CHUNK = 1024  # number of frames read at a time\n",
    "    FORMAT = pyaudio.paInt16  # each frame is a 16-bit (2-byte) integer\n",
    "    CHANNELS = 2  # 2 samples per frame\n",
    "    SECONDS = 5  # total recording time\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "    recorder = pyaudio.PyAudio()  # opens/closes audio streams\n",
    "\n",
    "    # configure and open audio stream for recording (input=True)\n",
    "    audio_stream = recorder.open(format=FORMAT, channels=CHANNELS, \n",
    "        rate=FRAME_RATE, input=True, frames_per_buffer=CHUNK)\n",
    "    audio_frames = []  # stores raw bytes of mic input\n",
    "    print('Recording 5 seconds of audio')\n",
    "\n",
    "    # read 5 seconds of audio in CHUNK-sized pieces\n",
    "    for i in range(0, int(FRAME_RATE * SECONDS / CHUNK)):\n",
    "        audio_frames.append(audio_stream.read(CHUNK))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "    print('Recording complete')\n",
    "    audio_stream.stop_stream()  # stop recording\n",
    "    audio_stream.close()  \n",
    "    recorder.terminate()  # release underlying resources used by PyAudio\n",
    "\n",
    "    # save audio_frames to a WAV file\n",
    "    with wave.open(file_name, 'wb') as output_file:\n",
    "        output_file.setnchannels(CHANNELS)\n",
    "        output_file.setsampwidth(recorder.get_sample_size(FORMAT))\n",
    "        output_file.setframerate(FRAME_RATE)\n",
    "        output_file.writeframes(b''.join(audio_frames))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function `play_audio` Using Features of **`pydub`** and **`pydub.playback`** Modules \n",
    "```python\n",
    "def play_audio(file_name):\n",
    "    \"\"\"Use the pydub module (pip install pydub) to play a WAV file.\"\"\"\n",
    "    sound = pydub.AudioSegment.from_wav(file_name)  # load audio\n",
    "    pydub.playback.play(sound)  # play audio\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the `run_translator` Function\n",
    "* **`run_translator`** called only when **`SimpleLanguageTranslator.py`** executes as a script:\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    run_translator()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.3 Watson Services \n",
    "* **Run the demos** to see the services in action\n",
    "* [Links to each Watson service’s documentation and API reference](https://cloud.ibm.com/developer/watson/documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Watson Assistant](https://cloud.ibm.com/catalog/services/watson-assistant) \n",
    "* Build **chatbots** and **virtual assistants** &mdash; users interact via **natural language text**\n",
    "* Can be **trained** for specific scenarios\n",
    "    * Train a **Weather chatbot** to respond to questions like, “What is the weather forecast for New York City?” \n",
    "    * Train a **customer service** chatbot to **answer customer questions**, **route customers to the correct department**, ...\n",
    "* Resources\n",
    "    * [Typical \"intents\"](https://cloud.ibm.com/docs/services/assistant?topic=assistant-catalog)\n",
    "    * [IBM Code Bot Exchange](https://developer.ibm.com/code/exchanges/bots/)&mdash;get existing bots and post your own\n",
    "    * [Other bot resources](https://cloud.ibm.com/docs/services/assistant?topic=assistant-resources#developer-resources)  \n",
    "* [**Try the demo**](https://watson-assistant-demo.ng.bluemix.net/) to see some sample interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Visual Recognition](https://cloud.ibm.com/catalog/services/visual-recognition) \n",
    "* Enables apps to **locate and understand information in images and video**\n",
    "    * colors\n",
    "    * objects\n",
    "    * faces\n",
    "    * text\n",
    "    * food\n",
    "    * inappropriate content\n",
    "* Use **predefined models** or **train/use your own**\n",
    "* [**Try the demo**](https://www.ibm.com/watson/services/visual-recognition/demo/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Speech to Text](https://cloud.ibm.com/catalog/services/speech-to-text)\n",
    "* Converts **speech audio files** to **text transcriptions**  \n",
    "* Can **“listen”** for keywords you specify\n",
    "* Can **distinguish among multiple speakers** \n",
    "* Use for **voice-controlled apps**, **transcribing live audio** and more\n",
    "* [**Try the demo**](https://speech-to-text-demo.ng.bluemix.net/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Text to Speech](https://cloud.ibm.com/catalog/services/text-to-speech) \n",
    "* **Synthesizes speech from text**\n",
    "* **Speech Synthesis Markup Language (SSML)** to control **voice inflection**, **cadence**, **pitch** and more\n",
    "* Currently supports \n",
    "    * English (U.S. and U.K.)\n",
    "    * French\n",
    "    * German\n",
    "    * Italian\n",
    "    * Spanish\n",
    "    * Portuguese\n",
    "    * Japanese\n",
    "* [**Try the demo**](https://text-to-speech-demo.ng.bluemix.net/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Language Translator](https://cloud.ibm.com/catalog/services/language-translator)\n",
    "* Translate text to other languages\n",
    "* Identify text's language (60+ supported languages)\n",
    "* [**Try the demo**](https://language-translator-demo.ng.bluemix.net/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Natural Language Understanding](https://cloud.ibm.com/catalog/services/natural-language-understanding) \n",
    "* Analyzes text for \n",
    "    * **sentiment** and **emotion** \n",
    "    * keywords **ranked by their relevance**\n",
    "* Can identify \n",
    "\t* **people**, **places**, **job titles**, **organizations**, **companies** and **quantities**\n",
    "\t* categories and concepts like **sports**, **government** and **politics**\n",
    "\t* **parts of speech** \n",
    "* Train for industry- and application-specific domains with **Watson Knowledge Studio** \n",
    "* [**Try the demo**](https://natural-language-understanding-demo.ng.bluemix.net/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Personality Insights](https://cloud.ibm.com/catalog/services/personality-insights) \n",
    "* Analyzes text for **personality traits**\n",
    "* \"Gain insight into how and why people think, act, and feel the way they do.\"\n",
    "* **Target product advertising** at the people most likely to purchase those products \n",
    "* [**Try the demo**](https://personality-insights-demo.ng.bluemix.net/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.4 Additional Services and Tools "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Watson Studio](https://cloud.ibm.com/catalog/services/data-science-experience)\n",
    "* For **creating and managing** Watson projects and for **collaborating with others** on those projects\n",
    "    * Add and prepare data for analysis \n",
    "    * Create **Jupyter Notebooks** for interacting with data\n",
    "    * **Create and train models** \n",
    "    * Work with Watson’s **deep-learning** capabilities\n",
    "* Offers a **single-user Lite tier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [**Preconfigured Watson Studio projects**](https://dataplatform.cloud.ibm.com/) \n",
    "* Click **Create a project** to view them: \n",
    "\t* **Standard**—“Work with any type of asset. Add services for analytical assets as you need them.”\n",
    "\t* **Data Science and AutoAI**—“**Analyze and model data** to **discover insights** or **generate predictions**.”\n",
    "\t* **Visual Recognition**—“**Tag and classify visual content** using the **Watson Visual Recognition service**.”\n",
    "\t* **Deep Learning**—“**Build neural networks** and **deploy deep learning models**.”\n",
    "\t* **Modeler**—“Build modeler flows to **train SPSS models** or **design deep neural networks**.”\n",
    "\t* **Business Analytics**—“Create **visual dashboards** from your data to gain insights faster.”\n",
    "\t* **Data Engineering**—“**Combine**, **cleanse**, **analyze**, and **shape data** using **Data Refinery**.”\n",
    "\t* **Streams Flow**—“**Ingest and analyze streaming data** using the **Streaming Analytics service**.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Knowledge Studio](https://cloud.ibm.com/catalog/services/knowledge-studio) \n",
    "* Various Watson services work with **predefined models**\n",
    "* Also can provide **custom models** trained for specific industries or applications \n",
    "* **Knowledge Studio** helps you **build custom models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Machine Learning](https://cloud.ibm.com/catalog/services/machine-learning) \n",
    "* **Add predictive capabilities to your apps** via popular **machine-learning frameworks**\n",
    "    * **Tensorflow**, **Keras**, **scikit-learn** and others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Knowledge Catalog](https://medium.com/ibm-watson/introducing-ibm-watson-knowledge-catalog-cf42c13032c1) \n",
    "* Among its features [\\[7\\]](https://dataplatform.cloud.ibm.com/docs/content/wsj/catalog/overview-wkc.html)\n",
    "\t* Central access to an enterprise’s local and **cloud-based data** and **machine learning models**\n",
    "\t* **Watson Studio support** so users can **find and access data**, then easily use it in **machine-learning projects**\n",
    "\t* **Secure** access to specific data \n",
    "\t* Support for over 100 **data cleaning and wrangling operations**\n",
    "\t* And more "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Cognos Analytics](https://www.ibm.com/products/cognos-analytics) \n",
    "* Uses **AI and machine learning** to discover and visualize information in your data, **without any programming** \n",
    "* Provides a **natural-language interface** that **enables you to ask questions** \n",
    "    * **Cognos Analytics** answers using knowledge it gathers from your data\n",
    "* Has a **30-day free trial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.7 Watson Resources\n",
    "* IBM provides a wide range of **developer resources** to help you familiarize yourself with their services and use them to build applications effectively. \n",
    "\n",
    "### [Watson Services Documentation](https://cloud.ibm.com/developer/watson/documentation)\n",
    "* **Each service’s documentation** includes some or all of the following:\n",
    "    * **getting started tutorial**\n",
    "    * **video overview** of the service\n",
    "    * **service demo**\n",
    "    * links to more **how-to** and **tutorial documents**\n",
    "    * **sample apps**\n",
    "* **Python** tab shows **Python-specific documentation** and **code samples**  \n",
    "* **API reference** explains **service options** and **responses** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Watson Learning Resources Page](https://cloud.ibm.com/developer/watson/learning-resources)\n",
    "* **Blog posts on Watson features** and how **Watson and AI** are being used in industry\n",
    "* **Watson’s GitHub repository** (**developer tools**, **SDKs** and **sample code**)\n",
    "* [**Watson YouTube channel**](https://www.youtube.com/user/IBMWatsonSolutions/) \n",
    "    * **Hundreds of videos** showing **how to use** all aspects of Watson \n",
    "    * Spotlight videos showing **how Watson is being used in industry**\n",
    "* **Code patterns**, “roadmaps for solving complex programming challenges” "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBM Redbooks Cover IBM Cloud and Watson Services in Detail\n",
    "* [Essentials of Application Development on IBM Cloud](http://www.redbooks.ibm.com/abstracts/sg248374.html)\n",
    "* [Building Cognitive Applications with IBM Watson Services: Volume 1 **Getting Started**](http://www.redbooks.ibm.com/abstracts/sg248387.html)\n",
    "* [Building Cognitive Applications with IBM Watson Services: Volume 2 **Conversation** (now called Watson Assistant)](http://www.redbooks.ibm.com/abstracts/sg248394.html)\n",
    "* [Building Cognitive Applications with IBM Watson Services: Volume 3 **Visual Recognition**](http://www.redbooks.ibm.com/abstracts/sg248393.html)\n",
    "* [Building Cognitive Applications with IBM Watson Services: Volume 4 **Natural Language Classifier**](http://www.redbooks.ibm.com/abstracts/sg248391.html)\n",
    "* [Building Cognitive Applications with IBM Watson Services: Volume 5 **Language Translator**](http://www.redbooks.ibm.com/abstracts/sg248392.html)\n",
    "* [Building Cognitive Applications with IBM Watson Services: Volume 6 **Speech to Text and Text to Speech**](http://www.redbooks.ibm.com/abstracts/sg248388.html)\n",
    "* [Building Cognitive Applications with IBM Watson Services: Volume 7 **Natural Language Understanding** ](http://www.redbooks.ibm.com/abstracts/sg248398.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#000; background-color:#000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Info \n",
    "* See Lesson 13 in [**Python Fundamentals LiveLessons** here on O'Reilly Online Learning](https://learning.oreilly.com/videos/python-fundamentals/9780135917411)\n",
    "* See Chapter 13 in [**Python for Programmers** on O'Reilly Online Learning](https://learning.oreilly.com/library/view/python-for-programmers/9780135231364/)\n",
    "* See Chapter 14 in [**Intro Python for Computer Science and Data Science** on O'Reilly Online Learning](https://learning.oreilly.com/library/view/intro-to-python/9780135404799/)\n",
    "* Interested in a print book? Check out:\n",
    "\n",
    "| Python for Programmers<br>(640-page professional book) | Intro to Python for Computer<br>Science and Data Science<br>(880-page college textbook)\n",
    "| :------ | :------\n",
    "| <a href=\"https://amzn.to/2VvdnxE\"><img alt=\"Python for Programmers cover\" src=\"../images/PyFPCover.png\" width=\"150\" border=\"1\"/></a> | <a href=\"https://amzn.to/2LiDCmt\"><img alt=\"Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud\" src=\"../images/IntroToPythonCover.png\" width=\"159\" border=\"1\"></a>\n",
    "\n",
    ">Please **do not** purchase both books&mdash;_Python for Programmers_ is a subset of _Intro to Python for Computer Science and Data Science_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy; 1992-2024 by Pearson Education, Inc. All Rights Reserved. The content in this notebook is based on the book [**Python for Programmers**](https://amzn.to/2VvdnxE)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

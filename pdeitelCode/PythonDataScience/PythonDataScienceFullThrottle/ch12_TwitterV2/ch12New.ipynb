{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 12. Data Mining Twitter\n",
    "> [Chapter 12, Data Mining Twitter (Updated for the Twitter v2 APIs)](https://deitel.com/wp-content/uploads/2022/09/python-for-programmers-chapter-12-data-mining-twitter-v2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Objectives\n",
    "* **Data-mine Twitter** with **Tweepy** library\n",
    "* Use various **Twitter v2** API methods\n",
    "* **Get information** about a specific Twitter account\n",
    "* **Search for past tweets** that meet your criteria\n",
    "* **Sample the stream of live tweets** as they’re happening\n",
    "* **Request additional metadata** in Twitter responses via the Twitter v2 API’s **expansions** and **fields**\n",
    "* **Clean and preprocess tweets** to prepare them for analysis\n",
    "* **Translate foreign language tweets** into English and to perform **sentiment analysis** on tweets\n",
    "* **Spot trends** with the Twitter v1.1 **Trends API**\n",
    "* **Map tweets** using **folium** and OpenStreetMap map tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.1 Introduction \n",
    "* Popular **big-data source**  \n",
    "* **Data mining** &mdash; searching large collections of data for **insights**\n",
    "* **Sentiment** in tweets can help **make predictions**  \n",
    "    * **Stock prices**\n",
    "    * **Election results**\n",
    "    * Likely **revenues** for a **new movie**\n",
    "    * **Success** of a company’s **marketing campaign**\n",
    "* Spot **faults in competitors’ products** \n",
    "* Spot **trending topics**\n",
    "* **Connect to Twitter** with easy-to-use **Web services**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Is Twitter?\n",
    "* Tweets\n",
    "    * Short messages\n",
    "    * Initially limited to **140 characters**\n",
    "    * Now limited to **280 characters**\n",
    "* Anyone can generally choose to follow anyone else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Statistics\n",
    "* [Hundreds of millions of tweets are sent every day with many thousands sent per second](https://www.worldometers.info/)\n",
    "* Can **tap into the live stream** of tweets\n",
    "    * Like **“drinking from a fire hose”** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Twitter and Big Data \n",
    "* A **favorite big data source** for researchers and business people worldwide\n",
    "* **Free** access to a small portion of recent tweets\n",
    "* Can pay for access to much larger portions the all-time tweets database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.2 Overview of the Twitter APIs \n",
    "* **Web services** are methods that you call in the **cloud**\n",
    "* Each method has a **web service endpoint** represented by a **URL**\n",
    "* **Caution**: Internet connections can be lost, services can change and some services are not available in all countries, so **apps can be brittle**\n",
    "* **API categories** we'll look at\n",
    "    * **Users API** — Access information about **Twitter user accounts**\n",
    "    * **Tweets API** — Search through **past tweets**, access **live tweet streams**\n",
    "    * **Trends API (Twitter v1.1)** — Find locations and lists of **trending topics**\n",
    "* **Additional Twitter API categories**  \n",
    ">https://developer.twitter.com/en/docs/api-reference-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate Limits: A Word of Caution \n",
    "* Twitter expects developers to use its services responsibly\n",
    "* **Understand rate limits** before using any method\n",
    "    * Twitter may **block you** for repeated violations\n",
    "    * **Tweepy** can be configured to **wait when it encounters rate limits**\n",
    "* Some methods list both **user rate limits** and **app rate limits**\n",
    "    * We use **app rate limits** in the demos\n",
    "    * **User rate limits** are for apps that enable individuals to log into their Twitter accounts\n",
    "* [Details on rate limiting](https://developer.twitter.com/en/docs/basics/rate-limiting)\n",
    "* [Specific rate limits on individual API methods](https://developer.twitter.com/en/docs/basics/rate-limits) — also see each API method’s documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Restrictions\n",
    "* **Follow Twitter’s rules/regulations** \n",
    "\t* Terms of service — https://twitter.com/tos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.3 Creating a Twitter Account\n",
    "* [Apply for a developer account](https://developer.twitter.com/) to use the APIs\n",
    "* Every application is subject to approval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Developer Account Levels\n",
    "https://developer.twitter.com/en/products/twitter-api\n",
    "* Some Twitter v2 APIs are accessible only to Elevated-level and higher accounts. \n",
    "    * **Essentials** — “The best way to get started quickly, test, and build across all endpoints.”\n",
    "    * **Elevated** — “More access for solutions that are beginning to experience growth or who prefer to work with multiple App environments.”\n",
    "    * **Academic Research** — “Access to public data on nearly any topic to advance research objectives of Master’s students, doctoral candidates, post-docs, and faculty at an academic institution or university.”\n",
    "* Twitter documentation specifies the minimum account level and the rate-limit differences between levels, if any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a Developer Account Application Type\n",
    "* **Professional**, **Hobbyist**, and **Academic Research** use\n",
    "    * choose the type most appropriate for your use case\n",
    "    * For our examples, can choose **Hobbyist** then **Exploring the API**\n",
    "* If asked to apply for an **Elevated** application, click **Get started**, then:\n",
    "    1. On the **Basic info** tab, fill in the form with your information and click **Next**.\n",
    "    2. On the **Intended use** tab, describe how you intend to use the APIs. \n",
    "    3. Answer the other questions provided—For this chapter’s examples, you will not \n",
    "        * use the tweet, retweet, like, follow or direct message functionality\n",
    "        * will not display tweets or aggregate data about Twitter content outside of Twitter\n",
    "        * will not make Twitter content available to a government entity\n",
    "    4. Click **Next** to review your answers, then click **Next** again. \n",
    "    5. Carefully read and agree to Twitter’s **Developer agreement & policy**, then click **Submit** to complete the application. You will be asked to confirm your email address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essentials Level Accounts and the Twitter v1.1 APIs\n",
    "* As of mid-2022, Twitter requires new developer accounts to use the Twitter v2 APIs\n",
    "* Twitter has not yet migrated some v1.1 APIs to v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.5 What’s in a Twitter API Response?\n",
    "* Twitter API methods return **JSON (JavaScript Object Notation)** objects\n",
    "* Text-based **data-interchange format** \n",
    "* Represents objects as **collections of name–value pairs** (like dictionaries)\n",
    "* Commonly used in web services\n",
    "* Human and computer readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.5 What’s in a Twitter API Response? (cont.)\n",
    "* **JSON object format**:\n",
    "> ```\n",
    "> {propertyName1: value1, propertyName2: value2}\n",
    "> ```\n",
    "* **JSON array format (like Python list)**:\n",
    "> ```\n",
    "> [value1, value2, value3]\n",
    "> ```\n",
    "* **Tweepy handles the JSON for you** behind the scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Properties of a Tweet Object\n",
    "Twitter returns a JSON object that, by default, contains \n",
    "* the tweet’s unique ID number \n",
    "* its text (up to a maximum of 280 characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Metadata and the Twitter v1.1 APIs \n",
    "In Twitter v1.1 APIs, a tweet’s JSON object automatically included many additional metadata attributes that described aspects of the tweet, such as:\n",
    "* when it was created, \n",
    "* who created it, \n",
    "* lists of the hashtags, URLs, @-mentions and media (such as images and videos) included in the tweet,\n",
    "* and more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter v2 API Expansions and Fields \n",
    "* Now must use **fields** and **expansions** to request metadata your app requires\n",
    "* **Fields** are **additional metadata attributes** you’d like Twitter to return to your app\n",
    "* When you get a tweet, you might need \n",
    "    * the unique `author_id` attribute, indicating a tweet’s sender\n",
    "    * the tweet’s `created_at` attribute, indicating when the user sent the tweet was sent\n",
    "* Complete list of tweet fields, visit\n",
    "> https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter v2 API Expansions and Fields \n",
    "* Some **fields** are associated with **other metadata objects** with their own fields\n",
    "* Associated with a tweet’s **`author_id`** attribute is a **user JSON object** \n",
    "* Use an **Expansion** to request associated metadata objects\n",
    "* Each will contain its default attributes\n",
    "    * For a user object, these would be the user’s **unique id number**, **name** and **username**\n",
    "    * Can request more from the list of user fields \n",
    "    > https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user\n",
    "* **Overview of all JSON objects** Twitter APIs return, and links to details\n",
    "> https://developer.twitter.com/en/docs/twitter-api/data-dictionary/introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample JSON for the NASA Account’s 10 Most Recent Tweets\n",
    "* Some of the JSON response to a request for recent tweets from `@NASA`\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"id\": \"1562156100136292352\",\n",
    "      \"text\": \"RT @NASAInSight: Thanks again for all the kind \n",
    "               thoughts you’ve been sending. There’s still \n",
    "               time to write me a note for the mission team to…\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"1561886047331487744\",\n",
    "      \"text\": \"We see Martian dust devils (whirlwinds) from the \n",
    "              ground, as in this shot from the Opportunity rover\n",
    "              in 2016, left. From space, we can see the tracks \n",
    "              they leave behind, as in this view of dunes from \n",
    "              Mars Reconnaissance Orbiter in 2009, right. More: \n",
    "              https://t.co/kd1BNEDBUD https://t.co/RxeKTI5Fv5\"\n",
    "    },\n",
    "    ...\n",
    "  ],\n",
    "  \"meta\": {\n",
    "    \"result_count\": 10,\n",
    "    \"newest_id\": \"1562156100136292352\",\n",
    "    \"oldest_id\": \"1555635141728382976\",\n",
    "    \"next_token\": \"7140dibdnow9c7btw422nm76p6owdso7rqahg96mulyd2\"\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.6 Installing `tweepy`, `geopy`, `folium` and `deep-translator`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Tweepy \n",
    "* [**Tweepy library**](http://www.tweepy.org/) — **one of the most popular Python Twitter clients**\n",
    "* Easy access to Twitter’s capabilities\n",
    "* [Tweepy’s documentation](https://docs.tweepy.org/en/stable/)\n",
    "> `pip install tweepy`\n",
    "* Windows users **should run the Anaconda Prompt as an Administrator**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing geopy \n",
    "* One function from our `tweetutilities.py` file (in the ch13 folder) depends on [**geopy**](https://github.com/geopy/geopy) (a geocoding library we'll use later to plot tweet locations on a map\n",
    ">`conda install -c conda-forge geopy`\n",
    "* Windows users **should run the Anaconda Prompt as an Administrator**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### OpenMapQuest Geocoding API\n",
    "* Section 12.15 uses the **OpenMapQuest Geocoding API** to convert locations, such as **Boston, MA**, into their latitudes and longitudes, such as **42.3602534** and **-71.0582912**, for plotting on maps\n",
    "* Currently allows **15,000 transactions per month** on their free tier\n",
    "* Sign up at \n",
    "> https://developer.mapquest.com/\n",
    "* Go to https://developer.mapquest.com/user/me/apps \n",
    "    * Click **Create a New Key**, fill in the **App Name** field with a name of your choosing, leave the **Callback URL** empty and click **Create App** to create an API key\n",
    "    * Click your app’s name to see your consumer key\n",
    "    * In the `keys.py` file, store the consumer key by replacing `YourKeyHere` in the line\n",
    "    > `mapquest_key = 'YourKeyHere'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folium Library and Leaflet.js JavaScript Mapping Library\n",
    "* Section 12.15 uses folium to create an interactive map\n",
    "> https://github.com/python-visualization/folium\n",
    "\n",
    "> `pip install folium`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps from OpenStreetMap.org\n",
    "* Leaflet.js uses open-source maps from `OpenStreetMap.org`. \n",
    "* Copyrighted by the OpenStreetMap.org contributors\n",
    "* www.openstreetmap.org/copyright \n",
    "* www.opendatacommons.org/licenses/odbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deep-translator Library\n",
    "Supports several translation services\n",
    "> `pip install -U deep_translator`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.7 Authenticating with Twitter Via Tweepy to Access Twitter v2 APIs\n",
    "* A **Tweepy `Client` object** is your gateway to using the Twitter v2 APIs\n",
    "* Must first **authenticate with Twitter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before executing this cell, ensure that your copy of keys.py \n",
    "# contains your Twitter credentials as described earlier\n",
    "import keys  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a `Client` Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To use the Twitter v2 APIs, **create a `Client` object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token=keys.bearer_token,\n",
    "                       wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `bearer_token` is your bearer token \n",
    "* `wait_on_rate_limit=True` lets Tweepy **manage rate limits** for you\n",
    "    * For most Twitter APIs, the rate-limit interval is 15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.8 Getting Information About a Twitter Account\n",
    "* `Client` object’s `get_user` method gets a `tweepy.Response` object containing information about a `@NASA`’s Twitter account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unauthorized",
     "evalue": "401 Unauthorized\nUnauthorized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnauthorized\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nasa \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43musername\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNASA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpublic_metrics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pydsft/lib/python3.10/site-packages/tweepy/client.py:2441\u001b[0m, in \u001b[0;36mClient.get_user\u001b[0;34m(self, id, username, user_auth, **params)\u001b[0m\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID or username is required\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2442\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpansions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtweet.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser.fields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_auth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_auth\u001b[49m\n\u001b[1;32m   2445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pydsft/lib/python3.10/site-packages/tweepy/client.py:129\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[0;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_request\u001b[39m(\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m, method, route, params\u001b[38;5;241m=\u001b[39m{}, endpoint_parameters\u001b[38;5;241m=\u001b[39m(), json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m     data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_auth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    126\u001b[0m ):\n\u001b[1;32m    127\u001b[0m     request_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_params(params, endpoint_parameters)\n\u001b[0;32m--> 129\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_auth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_auth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_type \u001b[38;5;129;01mis\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/pydsft/lib/python3.10/site-packages/tweepy/client.py:98\u001b[0m, in \u001b[0;36mBaseClient.request\u001b[0;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequest(response)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Unauthorized(response)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Forbidden(response)\n",
      "\u001b[0;31mUnauthorized\u001b[0m: 401 Unauthorized\nUnauthorized"
     ]
    }
   ],
   "source": [
    "nasa = client.get_user(username='NASA',\n",
    "    user_fields=['description', 'public_metrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `get_user` with the `username` keyword argument calls Twitter API method \n",
    "> `/2/users/by/username/:username`\n",
    "* Returns JSON data that Tweepy converts into a **`tweepy.Response`** \n",
    "    * Contains account’s **ID number**, **name** and **user name** by default\n",
    "* Can request additional fields via the **`user_fields`** keyword argument\n",
    "    * We requested the account’s **`description`** and **`public_metrics`**\n",
    "* Complete **list of user fields**\n",
    "> https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user\n",
    "* **Rate limit** for `/2/users/by/username/:username`\n",
    "    * Can call up to 900 times every 15 minutes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `tweepy.Response` Object\n",
    "* Contains four fields:\n",
    "    * **`data`** — contains the data returned by Twitter, including any additional fields you request  \n",
    "    * **`includes`** — contains related objects specified via the method’s `expansions` parameter \n",
    "    * **`errors`** — information about any errors that occurred\n",
    "    * **`meta`** — method-specific information that can be useful in processing the response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a User’s Basic Account Information\n",
    "* For a **user JSON object**, `Response`’s `data` attribute is a **named tuple** containing default fields\n",
    "    * `id` is the account’s unique ID number.\n",
    "    * `name` is the name associated with the user’s account.\n",
    "    * `username` is the user’s Twitter handle (`@NASA`) \n",
    "* Additional `user_fields` `description` and `public_metrics` (discussed momentarily) also are in the `Response` object’s `data` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa.data.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa.data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa.data.username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa.data.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Number of Accounts That Follow This Account and the Number of Accounts This Account Follows\n",
    "* **`public_metrics`** are returned as a dictionary with keys\n",
    "    * **`'followers_count'`** — number of users who follow this account, \n",
    "    * **`'following_count'`** — number of users that this account follows, \n",
    "    * **`'tweet_count'`** — total number of tweets (and retweets) sent by this user\n",
    "    * **`'listed_count'`** — total number of Twitter lists that include this user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa.data.public_metrics['followers_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa.data.public_metrics['following_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Your Own Account’s Information\n",
    "* Get via `Client` object’s `get_me` method\n",
    "> `me = client.get_me()`\n",
    "* Returns a **User object** for the account you used to authenticate with Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 12.9 Intro to Tweepy `Paginator`s: Getting More than One Page of Results \n",
    "* Twitter API methods often **return collections of objects**\n",
    "    * tweets sent by a particular user\n",
    "    * tweets matching specified search criteria \n",
    "    * tweets in a user’s timeline (tweets sent by a user and by other accounts that user follows)\n",
    "* Each Twitter API can return a maximum number of items per call\n",
    "    * known as a **page of results**\n",
    "* Tweepy **`Paginator`** handles paging details\n",
    "* Invokes a specified `Client` method and checks whether there is another page of results\n",
    "    * If so, the `Paginator` automatically calls the method again to get next page\n",
    "    * Continues (subject to the method’s rate limits) until there are no more results to process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.9.1 Determining an Account’s Followers  \n",
    "* Use a `Paginator` to invoke the `Client` object’s `get_users_followers` method\n",
    "* Calls the Twitter API’s method\n",
    "> `/2/users/:id/followers`\n",
    "* Returns followers in groups of 100 by default\n",
    "* Can request up to 1000 at a time\n",
    "* We’ll grab 10 of NASA’s followers, five at a time, so we receive two pages of results\n",
    "* Create a list to store the followers’ Twitter user names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a `Paginator`\n",
    "* `Paginator` to call `get_users_followers` for NASA’s account  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator = tweepy.Paginator(\n",
    "   client.get_users_followers, nasa.data.id, max_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* arguments are the method to call and any arguments that should be passed to that method\n",
    "    * `client.get_users_followers` indicates that the `Paginator` will call the `client` object’s `get_users_followers` method, \n",
    "    * `nasa.data.id` — ID number (obtained in Section 12.8) of the NASA Twitter account for which we’ll get followers, and \n",
    "    * `max_results=5` — results per page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Results\n",
    "* Use the `Paginator` to get some followers\n",
    "    * `paginator.flatten(10)` initiates the call to `client.get_users_followers`\n",
    "    * `10` indicates number of results to obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for follower in paginator.flatten(limit=10):\n",
    "    followers.append(follower.username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Followers:', \n",
    "    ' '.join(sorted(followers, key=lambda s: s.lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Paging\n",
    "* `flatten` automatically “pages” through the results by making multiple calls to `client.get_users_followers` as necessary\n",
    "* `flatten` makes multiple pages appear to be a sequence of results\n",
    "* If you do not specify an argument to `flatten`, the `Paginator` attempts to get all of the account’s followers\n",
    "    * This could take significant time due to Twitter’s rate limits \n",
    "    * `/2/users/:id/followers` can return a maximum of 1000 followers at a time, and Twitter allows up to 15 calls every 15 minutes\n",
    "    * 15,000 followers every 15 minutes using Twitter’s free APIs\n",
    "    * At 60,000 followers per hour, it would take over 40 days to get all of NASA’s followers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 12.9.2 Determining Whom an Account Follows \n",
    "* `Client` object’s `get_users_following` method calls the Twitter API’s \n",
    "`/2/users/:id/following` method to get a list of Twitter users an account follows\n",
    "* Returns groups of 100 by default, but you can request up to 1000 at a time\n",
    "* Can call this method up to 15 times every 15 minutes\n",
    "* Get 10 accounts that NASA follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "following = []\n",
    "\n",
    "paginator = tweepy.Paginator(\n",
    "    client.get_users_following, nasa.data.id, max_results=5)\n",
    "\n",
    "for user_followed in paginator.flatten(limit=10):\n",
    "    following.append(user_followed.username)\n",
    "\n",
    "print('Following:', \n",
    "      ' '.join(sorted(following, key=lambda s: s.lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 12.9.3 Getting a User’s Recent Tweets \n",
    "* `Client` method `get_users_tweets` returns a `tweepy.Response` containing tweets from a specified user\n",
    "* Calls the Twitter API’s `/2/users/:id/tweets` method\n",
    "* Returns the most recent 10 tweets but can between 5 and 100 at a time\n",
    "* Can return only an account’s 3200 most recent tweets\n",
    "* May call this method up to 1500 times every 15 minutes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 12.9.3 Getting a User’s Recent Tweets (cont.) \n",
    "* The `data` attribute of the `tweepy.Response` contains a list of the returned tweets\n",
    "    * Each object in that list has a dictionary `data` attribute containing the keys `'id'` and `'text'` for each tweet’s unique ID and its text\n",
    "* Display five tweets from the `@NASA` account using its ID number that we obtained previously: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nasa_tweets = client.get_users_tweets(\n",
    "     id=nasa.data.id, max_results=5)\n",
    "\n",
    "for tweet in nasa_tweets.data:\n",
    "    print(f\"NASA: {tweet.data['text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 12.9.3 Getting a User’s Recent Tweets (cont.)\n",
    "* We called the `get_users_tweets` method directly and used the keyword argument `max_results` to specify the number of tweets to retrieve\n",
    "* For more than the maximum number of tweets per call (100), use a `Paginator` to call `get_users_tweets` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing Recent Tweets from Your Own Timeline\n",
    "* `Client` method `get_home_timeline` gets tweets from your home timeline\n",
    "    * your tweets and retweets, as well as tweets and retweets from the Twitter users you follow\n",
    "> `client.get_home_timeline()`\n",
    "* Calls Twitter’s `/2/users/:id/timelines/reverse_chronological` method \n",
    "* Returns up to 100 tweets by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 12.10 Searching Recent Tweets; Intro to Twitter v2 API Search Operators \n",
    "* `Client` method `search_recent_tweets` \n",
    "    * Returns tweets from the last seven days that match a query string you provide\n",
    "    * Calls Twitter method `/2/tweets/search/recent`, \n",
    "    * **Returns a minimum of 10 tweets** at a time (the default) but **can return up to 100** (specified with keyword argument **`max_results`**)\n",
    "    * It’s possible that fewer than 10 tweets will match the specified query string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Function `print_tweets` from `tweetutilities.py`\n",
    "* Receives the results of a call to API method `search` and for each tweet displays the user’s `screen_name` and the tweet’s `text`. \n",
    "* If the tweet is not in English and the `tweet.lang` is not `'und'` (undefined), we’ll also translate the tweet to English  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweetutilities import print_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def print_tweets(tweets):\n",
    "    # translator to autodetect source language and return English\n",
    "    translator = GoogleTranslator(source='auto', target='en')\n",
    "\n",
    "    \"\"\"For each tweet in tweets, display the username of the sender\n",
    "    and tweet text. If the language is not English, translate the text \n",
    "    with the deep-translator library's GoogleTranslator.\"\"\"\n",
    "    for tweet, user in zip(tweets.data, tweets.includes['users']):\n",
    "        print(f'{user.username}:', end=' ')\n",
    "\n",
    "        if 'en' in tweet.lang:\n",
    "            print(f'{tweet.text}\\n')\n",
    "        elif 'und' not in tweet.lang: # translate to English first\n",
    "            print(f'\\n  ORIGINAL: {tweet.text}')\n",
    "            print(f'TRANSLATED: {translator.translate(tweet.text)}\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for Specific Words\n",
    "* Call `Client` object’s `search_recent_tweets` method to search for 10 recent tweets about the Webb Space Telescope\n",
    "* Returns a `Response` object in which the data attribute contains a list of matching tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = client.search_recent_tweets(\n",
    "    query='Webb Space Telescope -is:retweet', \n",
    "    expansions=['author_id'], tweet_fields=['lang']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `query` keyword argument specifies the query string containing your search criteria\n",
    "* Twitter returns only each tweet’s unique ID and text by default\n",
    "* `'lang'` is an additional field you may request via the `tweet_fields` parameter\n",
    "* **Complete list of tweet fields**\n",
    "> https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet\n",
    "* The **expansion `'author_id'`** indicates that for each tweet, Twitter also should return the **user JSON object for the user who sent the tweet**—`id`, `name` and `username` by default\n",
    "* Tweepy places the **expansion objects** in the **`Response`’s `includes` dictionary attribute**\n",
    "    * For the `'author_id'` expansion, a **list of tweet authors** is stored with the key **`'users'`**\n",
    "    * **Each tweet has a corresponding user in this list**\n",
    "    * The following expression in line 8 of `print_tweets` creates tuples in which the first element represents a tweet and the second element represents the user object for the sender\n",
    "    > `zip(tweets.data, tweets.includes['users'])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Display the tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tweets(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching with Twitter v2 API Search Operators\n",
    "* Can use **Twitter search operators** in query strings to refine search results\n",
    "* **Max query-string length** is limited by your developer account type:\n",
    "    * For **Essentials** and **Elevated** accounts: up to **512 characters**\n",
    "    * For **Academic Research** accounts: up to **1024 characters**\n",
    "* Some operators are available only for Elevated accounts or higher\n",
    "* The Twitter v2 operators are categorized as **standalone** or **conjunction-required**\n",
    "    * **Standalone operators** can be used alone or combined with other operators in a query string\n",
    "    * **Conjunction-required operators** must be combined with at least one standalone operator in a query string\n",
    "* The following table shows several Twitter search operators, as well as logical AND, logical OR and logical negation capabilities\n",
    "    * parentheses can be used to group query-string subexpressions\n",
    "    * matching is performed using case-insensitive searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Example&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | Finds tweets containing |\n",
    "| --- | --- |\n",
    "| `python twitter` | Finds tweets containing `python` AND `twitter`. Spaces between query string terms and operators are implicitly treated as logical AND operations. In this query string, `python` and `twitter` are terms to search for—these are considered **standalone operators**.\n",
    "| `python OR twitter` \t| Finds tweets containing `python` `OR` `twitter` `OR` both. The logical `OR` operator is case-sensitive.\n",
    "| `planets -mars` \t| `-` (minus sign)—Finds tweets containing `planets` but not `mars`. The minus is the logical NOT operator and can be applied to any operator.\n",
    "| An emoji | Use emojis as standalone operators to find tweets containing those emojis. \n",
    "| `has:hashtags`, `has:links`, `has:mentions`, `has:media`, … | You can combine these **conjunction-required operators** with standalone operators to find tweets containing hashtags, links, mentions of other users, media and more. \n",
    "| `is:retweet`, `is:reply`, `is:verified`, … | You can combine these **conjunction-required operators** with standalone operators to determine whether a tweet is a retweet, a tweet is a reply, the sender is a verified Twitter account and more. \n",
    "| `place:\"New York City\"` | Finds tweets that were sent near `\"New York City\"`. Multiword places should be quoted as shown here. \n",
    "| `from:NASA` \t| Finds tweets from the account `@NASA`.\n",
    "| `to:NASA` \t| Finds tweets to the account `@NASA`. You also may use `to:id`, where `id` is the unique ID number of the user account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operator Documentation and Tutorial\n",
    "* All operators with examples of each  \n",
    "> https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\n",
    "* Twitter’s tutorial on building high-quality Twitter v2 API query strings to obtain the targeted results\n",
    "> https://developer.twitter.com/en/docs/tutorials/building-high-quality-filters\n",
    "* Twitter online tool to help you build Twitter v2 API query strings\n",
    "> https://developer.twitter.com/apitools/query?query="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Searching for Tweets From NASA Containing Links\n",
    "* Use `from` and `has:links` operators to get recent tweets from `NASA` that contain hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = client.search_recent_tweets(\n",
    "    query='from:NASA has:links', \n",
    "    expansions=['author_id'], tweet_fields=['lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tweets(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Searching for a Hashtag\n",
    "* Get tweets containing the hashtag `#metaverse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets = client.search_recent_tweets(query='#metaverse', \n",
    "    expansions=['author_id'], tweet_fields=['lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_tweets(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.11 Spotting Trends: Twitter Trends API\n",
    "**Note: At the time of this writing, Twitter had not yet migrated their Trending Topics APIs from v1.1 to v2. The v1.1 APIs used in this section are accessible only to Twitter Developer accounts with “Elevated” access and higher.**\n",
    "\n",
    "* If a topic **“goes viral,”** thousands or even millions of people could tweet about it\n",
    "* Twitter calls these **trending topics** and maintains lists of them worldwide\n",
    "* Via the Twitter v1.1 Trends API, you can get lists of locations with trending topics and lists of the top 50 trending topics for each location\n",
    "* To use the v1.1 APIs in Tweepy, initialize an object of class `OAuth2BearerHandler` with your bearer token, then create an `API` object that uses the `OAuth2BearerHandler` object to authenticate with Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuth2BearerHandler(keys.bearer_token)\n",
    "\n",
    "api = tweepy.API(auth=auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.11.1 Places with Trending Topics \n",
    "* See how to find places with trending topics: https://learning.oreilly.com/videos/python-fundamentals/9780135917411/9780135917411-PFLL_Lesson12_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.11.2 Getting a List of Trending Topics \n",
    "* Via Tweepy `API`’s **`get_place_trends` method** \n",
    "* Calls **Twitter Trends API’s [`trends/place` method](https://developer.twitter.com/en/docs/trends/trends-for-location/api-reference/get-trends-place)**\n",
    "* Returns top 50 trending topics for the location \n",
    "* [Look up WOEIDs](http://www.woeidlookup.com) \n",
    "* Look up WOEID’s programmatically using **Yahoo!’s web services** via [Python libraries like `woeid`](https://github.com/Ray-SunR/woeid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldwide Trending Topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_trends = api.get_place_trends(id=1)  # list containing one dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`'trends'` key** refers to a list of dictionaries representing each trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_list = world_trends[0]['trends']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each trend has **`name`**, **`url`**, **`promoted_content`** (whether it's an advertisement), **`query`** and **`tweet_volume`** keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Today's Worldwide Trending Topics (cont.)\n",
    "* For **trends with more than 10,000 tweets**, the `tweet_volume` is the number of tweets; otherwise, it’s `None`\n",
    "* Filter the list so that it contains only trends with more than 10,000 tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_list = [t for t in trends_list if t['tweet_volume']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sort the trends in _descending_ order by `tweet_volume`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_list.sort(key=itemgetter('tweet_volume'), reverse=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Today's Worldwide Trending Topics (cont.)\n",
    "* Display names of the **top five trending topics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trend in trends_list:\n",
    "    print(trend['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.12 Cleaning/Preprocessing Tweets for Analysis\n",
    "* **Data cleaning** is one of data scientists' most common tasks \n",
    "* Some NLP tasks for normalizing tweets\n",
    "    * Converting all text to the same case\n",
    "    * Removing `#` from hashtags, `@`-mentions, duplicates, hashtags\n",
    "    * Removing excess whitespace, punctuation, **stop words**, URLs\n",
    "    * Removing `RT` (retweet) and `FAV` (favorite) \n",
    "    * **Stemming** and **lemmatization**\n",
    "    * **Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [**tweet-preprocessor**](https://github.com/s/preprocessor) Library and TextBlob Utility Functions\n",
    "* `pip install tweet-preprocessor`\n",
    "* Can automatically remove any combination of:\n",
    "\n",
    "| Option | Option constant |\n",
    "| :--- | :--- |\n",
    "| **`OPT.MENTION`** | @-Mentions (e.g., `@nasa`) |\n",
    "| **`OPT.EMOJI`** | Emoji |\n",
    "| **`OPT.HASHTAG`** | Hashtag (e.g., `#mars`) |\n",
    "| **`OPT.NUMBER`** | Number |\n",
    "| **`OPT.RESERVED`** | Reserved Words (`RT` and `FAV`) |\n",
    "| **`OPT.SMILEY`** | Smiley |\n",
    "| **`OPT.URL`** | URL |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning a Tweet Containing a Reserved word and a URL\n",
    "* The tweet-preprocessor library’s module name is **`preprocessor`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.RESERVED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = 'RT A sample retweet with a URL https://nasa.gov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.clean(tweet_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 12.13 Twitter Streaming API\n",
    "* Your app can receive tweets as they occur in real-time\n",
    "* Based on the Twitter Statistics page at [InternetLiveStats.com](http://www.internetlivestats.com/twitter-statistics/)\n",
    "    * **over 10,000 tweets per second**\n",
    "    * approximately **880 million tweets per day**\n",
    "* Most developer accounts are subject to a **tweet cap** — a maximum number of tweets per month that an account’s Twitter apps can acquire using the Twitter APIs\n",
    "    * 500,000 for Essentials accounts \n",
    "    * two million for Elevated accounts\n",
    "    * academic research and paid accounts can get more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.13.1 Creating a Subclass of `StreamingClient` \n",
    "* A stream uses a **persistent** connection to **push** tweets to your app\n",
    "* Streaming rate varies, based on search criteria specified with **`StreamRule`s** \n",
    "* Twitter uses all the `StreamRule`s you set to find tweets, including those set previously\n",
    "* You may want to **delete existing `StreamRule`s before creating new ones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.13.1 Creating a Subclass of `StreamingClient` (cont.)\n",
    "* Create a subclass of Tweepy’s `StreamingClient` class to process the tweet stream\n",
    "* Tweepy calls the methods on an object of this class as it receives each new tweet (or other message, such as an error) from Twitter\n",
    "    * `on_connect(self)` is called when your app successfully connects to the Twitter stream\n",
    "    * `on_respone(self, response)` is called when a response arrives from the Twitter stream—`response` parameter is a Tweepy `StreamResponse` named tuple object containing the tweet data, any expansion objects you requested and more\n",
    "* `StreamingClient` already defines these and other \"on_\" methods \n",
    "* Override only the methods your app needs\n",
    "* `StreamingClient` methods\n",
    "> https://docs.tweepy.org/en/latest/streamingclient.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Class `TweetListener`\n",
    "`StreamingClient` subclass `TweetListener` is defined in `tweetlistener.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "```python\n",
    "# tweetlistener.py\n",
    "\"\"\"StreamingClient subclass that processes tweets as they arrive.\"\"\"\n",
    "from deep_translator import GoogleTranslator\n",
    "import tweepy\n",
    "\n",
    "class TweetListener(tweepy.StreamingClient):\n",
    "    \"\"\"Handles incoming Tweet stream.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Class `TweetListener`: `__init__` Method \n",
    "* called when you create a new `TweetListener` object\n",
    "* `bearer_token` is used to authenticate with Twitter\n",
    "* `limit` parameter is the number of tweets to process\n",
    "* Line 11: instance variable to track the number of tweets processed so far\n",
    "* Line 12: constant to store the limit\n",
    "* `GoogleTranslator` object for translating tweets into English\n",
    "* Line 17 passes the `bearer_token` to the superclass’s `__init__`\n",
    "\n",
    "```python\n",
    "    def __init__(self, bearer_token, limit=10):\n",
    "        \"\"\"Create instance variables for tracking number of tweets.\"\"\"\n",
    "        self.tweet_count = 0\n",
    "        self.TWEET_LIMIT = limit\n",
    "        \n",
    "        # GoogleTranslator object for translating tweets to English \n",
    "        self.translator = GoogleTranslator(source='auto', target='en')\n",
    "\n",
    "        super().__init__(bearer_token, wait_on_rate_limit=True)  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Class `TweetListener`: `on_connect` Method \n",
    "* Called when your app successfully connects to the Twitter stream\n",
    "\n",
    "```python\n",
    "    def on_connect(self):\n",
    "        \"\"\"Called when your connection attempt is successful, enabling \n",
    "        you to perform appropriate application tasks at that point.\"\"\"\n",
    "        print('Connection successful\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Class `TweetListener`: `on_response` Method \n",
    "* Called by when each tweet arrives\n",
    "* second parameter is a Tweepy `StreamResponse` named tuple object containing:\n",
    "    * `data` — the tweet’s attributes\n",
    "    * `includes` — any requested expansion objects\n",
    "    * `errors` — any errors that occurred\n",
    "    * `matching_rules` — `StreamRules` that the returned tweet matched\n",
    "* This example uses an expansion to include in the `StreamResponse` the user JSON object for each tweet’s sender\n",
    "    * Twitter also returns user objects for accounts mentioned in the tweet’s text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "    def on_response(self, response):\n",
    "        \"\"\"Called when Twitter pushes a new tweet to you.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # get username of user who sent the tweet\n",
    "            username = response.includes['users'][0].username\n",
    "            print(f'Screen name: {username}')\n",
    "            print(f'   Language: {response.data.lang}')\n",
    "            print(f' Tweet text: {response.data.text}')\n",
    "\n",
    "            if response.data.lang != 'en' and response.data.lang != 'und':\n",
    "                english = self.translator.translate(response.data.text)\n",
    "                print(f' Translated: {english}')\n",
    "\n",
    "            print()\n",
    "            self.tweet_count += 1 \n",
    "        except Exception as e:\n",
    "            print(f'Exception occured: {e}')\n",
    "            self.disconnect()\n",
    "            \n",
    "        # if TWEET_LIMIT is reached, terminate streaming\n",
    "        if self.tweet_count == self.TWEET_LIMIT:\n",
    "            self.disconnect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Line 29 gets the sender’s username\n",
    "    * List element 0 of `response.includes['users']` contains the tweet sender’s user object\n",
    "    * Subsequent elements would contain accounts mentioned in the tweet\n",
    "* Lines 30–32 display the tweet sender’s `username`, the tweet’s language (`lang`) and the tweet’s `text`\n",
    "* If necessary, lines 34–36 translate the tweet to English and display it\n",
    "* Line 39 increments `self.tweet_count`\n",
    "* Lines 45–46 determine whether to terminate streaming. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 12.13.2 Initiating Stream Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating a TweetListener \n",
    "* `StreamingClient` subclass `TweetListener` manages the connection to the Twitter stream and receives and processes the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tweetlistener import TweetListener\n",
    "\n",
    "tweet_listener = TweetListener(\n",
    "    bearer_token=keys.bearer_token, limit=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Redirecting the Standard Error Stream to the Standard Output Stream\n",
    "* When `StreamingClient` subclass’s `disconnect` method is called to terminate the tweet stream, the method sends the following message to `sys.stderr` which is not synchronized with the standard output stream\n",
    "> `Stream connection closed by Twitter`\n",
    "* Sometimes causes the preceding message to be interspersed with other messages that this app sends to the standard output stream\n",
    "* To prevent this, redirect the standard error stream to the standard output stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.stderr = sys.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deleting Existing Stream Rules\n",
    "* Twitter uses all the `StreamRule`s you’ve specified previously to filter the tweets it pushes to your app\n",
    "* Twitter does not automatically remove your `StreamRule`s after you terminate the tweet stream\n",
    "* If your app filters the tweet stream with different rules each time you run it, you should delete any existing `StreamRule`s before creating new ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Get the `StreamRule`s by calling your `StreamingClient`’s `get_rules` method\n",
    "    * `Response`’s `data` attribute contains a `list` of `StreamRule`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rules = tweet_listener.get_rules().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Get the rule IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# execute only if you have rules previously saved; \n",
    "# Twitter recently started deleting saved rules that have not been used recently\n",
    "rule_ids = [rule.id for rule in rules]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Call `StreamingClient`’s `delete_rules` method with a list of rule IDs to delete\n",
    "    * response contains a `'summary'` dictionary with information about the number of deleted rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# execute only if you have rules previously saved; \n",
    "tweet_listener.delete_rules(rule_ids)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating and Adding a Stream Rule\n",
    "* Create a rule to filter the live tweet stream looking for tweets about football\n",
    "* Then, add the rule\n",
    "    * `add_rules`’ Response contains a `'summary'` dictionary with information about the `StreamRule` you set and whether it was valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_rule = tweepy.StreamRule('football')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_listener.add_rules(filter_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Starting the Tweet Stream\n",
    "* `StreamingClient`'s `filter` method begins streaming \n",
    "    * `expansions` argument indicates that we’d like the response for each tweet to include the sender’s user JSON object\n",
    "    * `tweet_fields` argument indicates that the tweet’s language should be included in the responses tweet JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_listener.filter( \n",
    "    expansions=['author_id'], tweet_fields=['lang'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Asynchronous vs. Synchronous Streams\n",
    "* Tweepy supports asynchronous tweet streams by creating a subclass of `AsyncStreamingClient`\n",
    "* Allows your application to continue executing while your listener waits to receive tweets\n",
    "* Convenient in GUI applications, so users can continue interacting with other parts of the application while tweets arrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.14 Tweet Sentiment Analysis \n",
    "* Political researchers might use during elections to understand how people feel about specific politicians and issues, and **how they're likely to vote**\n",
    "* Companies might use to see what people are saying about their products and competitors’ products\n",
    "* Script `sentimentlistener.py` checks sentiment on a specified topic for a specified number of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run sentimentlistener.py football 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Class `SentimentListener`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Import the keys.py file and the libraries used throughout the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "# sentimentlisener.py\n",
    "\"\"\"Script that searches for tweets that match a search string\n",
    "and tallies the number of positive, neutral and negative tweets.\"\"\"\n",
    "import keys\n",
    "import preprocessor as p \n",
    "import sys\n",
    "from textblob import TextBlob\n",
    "import tweepy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Class `SentimentListener`: `__init__` Method\n",
    "* Receives:\n",
    "    * `bearer_token` for authentication\n",
    "    * `sentiment_dict` dictionary in which we’ll keep track of the tweet sentiments\n",
    "    * `topic` we’re searching for so we can ensure that it appears in the tweet text  \n",
    "    * `limit` of tweets to process (not including the ones we eliminate)\n",
    "* Each of these is stored in the current `SentimentListener` object (`self`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "class SentimentListener(tweepy.StreamingClient):\n",
    "    \"\"\"Handles incoming Tweet stream.\"\"\"\n",
    "\n",
    "    def __init__(self, bearer_token, sentiment_dict, topic, limit=10):\n",
    "        \"\"\"Configure the SentimentListener.\"\"\"\n",
    "        self.sentiment_dict = sentiment_dict\n",
    "        self.tweet_count = 0\n",
    "        self.topic = topic\n",
    "        self.TWEET_LIMIT = limit\n",
    "\n",
    "        # set tweet-preprocessor to remove URLs/reserved words\n",
    "        p.set_options(p.OPT.URL, p.OPT.RESERVED) \n",
    "        super().__init__(bearer_token, wait_on_rate_limit=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Method `on_response `\n",
    "* If the tweet is not a retweet (line 28):\n",
    "    * Line 29 gets and cleans the tweet’s text \n",
    "    * Lines 32–33 skip the tweet if it does not contain `topic` in the tweet text\n",
    "    * Lines 36–45 use a `TextBlob` to check the tweet’s sentiment and update the `sentiment_dict` accordingly\n",
    "    * Line 48 gets the sender’s `username` from `response.includes['users']` — we’ll use an expansion to include this user object \n",
    "    * Line 49 prints the tweet text preceded by `+` for positive sentiment, a space for neutral sentiment or `-` for negative sentiment\n",
    "    * Line 51 increments the `tweet_count`, and lines 54–55 check whether the app should disconnect from the tweet stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "    def on_response(self, response):\n",
    "        \"\"\"Called when Twitter pushes a new tweet to you.\"\"\"\n",
    "\n",
    "        # if the tweet is not a retweet\n",
    "        if not response.data.text.startswith('RT'):\n",
    "            text = p.clean(response.data.text) # clean the tweet\n",
    "\n",
    "            # ignore tweet if the topic is not in the tweet text\n",
    "            if self.topic.lower() not in text.lower():\n",
    "                return\n",
    "\n",
    "            # update self.sentiment_dict with the polarity\n",
    "            blob = TextBlob(text)\n",
    "            if blob.sentiment.polarity > 0:\n",
    "                sentiment = '+'\n",
    "                self.sentiment_dict['positive'] += 1 \n",
    "            elif blob.sentiment.polarity == 0:\n",
    "                sentiment = ' '\n",
    "                self.sentiment_dict['neutral'] += 1 \n",
    "            else:\n",
    "                sentiment = '-'\n",
    "                self.sentiment_dict['negative'] += 1 \n",
    "\n",
    "            # display the tweet\n",
    "            username = response.includes['users'][0].username\n",
    "            print(f'{sentiment} {username}: {text}\\n')\n",
    "\n",
    "            self.tweet_count += 1 # track number of tweets processed\n",
    "\n",
    "            # if TWEET_LIMIT is reached, terminate streaming\n",
    "            if self.tweet_count == self.TWEET_LIMIT:\n",
    "                self.disconnect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Main Application\n",
    "* The main application is defined in the function `main` (lines 57–87; discussed after the code), which is called by lines 90–91 when you execute the file as a script\n",
    "* `sentimentlistener.py` also can be imported into IPython or other modules to use class `SentimentListener` as we did with `TweetListener`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "def main():\n",
    "    # get search term and number of tweets\n",
    "    search_key = sys.argv[1]\n",
    "    limit = int(sys.argv[2]) # number of tweets to tally\n",
    "\n",
    "    # set up the sentiment dictionary\n",
    "    sentiment_dict = {'positive': 0, 'neutral': 0, 'negative': 0}\n",
    "\n",
    "    # create the StreamingClient subclass object\n",
    "    sentiment_listener = SentimentListener(keys.bearer_token, \n",
    "        sentiment_dict, search_key, limit)\n",
    "\n",
    "    # redirect sys.stderr to sys.stdout\n",
    "    sys.stderr = sys.stdout\n",
    "\n",
    "    # delete existing stream rules\n",
    "    rules = sentiment_listener.get_rules().data\n",
    "    rule_ids = [rule.id for rule in rules]\n",
    "    sentiment_listener.delete_rules(rule_ids)    \n",
    "\n",
    "    # create stream rule\n",
    "    sentiment_listener.add_rules(\n",
    "        tweepy.StreamRule(f'{search_key} lang:en'))\n",
    "\n",
    "    # start filtering English tweets containing search_key\n",
    "    sentiment_listener.filter(expansions=['author_id'])\n",
    "\n",
    "    print(f'Tweet sentiment for \"{search_key}\"')\n",
    "    print('Positive:', sentiment_dict['positive'])\n",
    "    print(' Neutral:', sentiment_dict['neutral'])\n",
    "    print('Negative:', sentiment_dict['negative'])\n",
    "\n",
    "# call main if this file is executed as a script\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* In `main`:\n",
    "    * Lines 59–60 get the command-line arguments\n",
    "    * Line 63 creates the `sentiment_dict` dictionary that keeps track of the tweet sentiments\n",
    "    * Lines 66–67 create the `SentimentListener` \n",
    "    * Line 70 redirects the standard error stream to the standard output stream\n",
    "    * Lines 73–75 delete any existing `StreamRule`s\n",
    "    * Lines 78–79 create a new `StreamRule` that searches for English (`lang:en`) tweets that match the `search_key`\n",
    "    * Line 82 starts the stream — `expansions` indicates that we’d like Twitter to include the tweet sender’s user object in the response\n",
    "    * Lines 84–87 display the sentiment report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.15 Geocoding and Mapping\n",
    "* Collect streaming tweets, then plot their locations on an interactive map\n",
    "* **Twitter disables precise location info (latitude/longitude) by default** (users must opt in to allowing Twitter to track locations) \n",
    "* Large percentage include the user’s home location information\n",
    "    * Sometimes invalid or fictitious \n",
    "* Map markers will show the sender's `location` and tweet text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### [**geopy** library](https://github.com/geopy/geopy)\n",
    "* Setup in Section 12.6\n",
    "* **Geocoding**&mdash;translate locations into **latitude** and **longitude**\n",
    "* **geopy** supports dozens of **geocoding web services**, many with **free or lite tiers**\n",
    "* We’ll use **OpenMapQuest geocoding service** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenMapQuest Geocoding API\n",
    "* Sign-up instructions in Section 12.6\n",
    "* Convert locations, such as **Boston, MA** into their **latitudes** and **longitudes**, such as **42.3602534** and **-71.0582912**, for plotting on maps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [**folium library**](https://github.com/python-visualization/folium) and Leaflet.js JavaScript Mapping Library\n",
    "* Setup in Section 12.6\n",
    "* For maps — uses **Leaflet.js JavaScript mapping library** to display maps in a web page \n",
    "* Folium save as HTML files that you can view in your web browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 12.15.1 Getting and Mapping the Tweets\n",
    "* We’ll use utility functions from our **`tweetutilities.py`** file and class **`LocationListener`** in **`locationlistener.py`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collections Required By LocationListener\n",
    "* a list (`tweets`) to store the data from the tweets we collect \n",
    "* a dictionary (`counts`) to track the total number of tweets we collect and the number that have location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [] \n",
    "\n",
    "counts = {'total_tweets': 0, 'locations': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LocationListener \n",
    "* Collect 50 tweets about `'football'`\n",
    "* `LocationListener` will use utility function `get_tweet_content` (located in `tweetutilities.py`; discussed in Section 12.15.2) to place in a dictionary the `username`, tweet `text` and user `location` from each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from locationlistener import LocationListener\n",
    "\n",
    "location_listener = LocationListener(\n",
    "    keys.bearer_token, counts_dict=counts, tweets_list=tweets,\n",
    "    topic='football', limit=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Redirect sys.stderr to sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.stderr = sys.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Existing StreamRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = location_listener.get_rules().data\n",
    "\n",
    "rule_ids = [rule.id for rule in rules]\n",
    "\n",
    "location_listener.delete_rules(rule_ids)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a StreamRule\n",
    "* Rule to get tweets in English (`lang:en`) about football "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_listener.add_rules(\n",
    "    tweepy.StreamRule('football lang:en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and Start the Stream of Tweets\n",
    "* start streaming the tweets\n",
    "    * expansion `'author_id'` gets information about the user who sent the tweet, including the `username`\n",
    "    * `user_fields` argument specifies that the user information should include the account’s `'location'` \n",
    "    * `tweet_fields` argument specifies additional information to include with each tweet—in this case, the tweet’s `language`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_listener.filter(expansions=['author_id'], \n",
    "    user_fields=['location'], tweet_fields=['lang'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Displaying the Location Statistics\n",
    "* check how many tweets we processed, how many had locations and the percentage that had locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['total_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['locations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{counts[\"locations\"] / counts[\"total_tweets\"]:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocoding the Locations\n",
    "* Use `get_geocodes` utility function (from `tweetutilities.py`; discussed in Section 12.15.2) to geocode the location of each tweet stored in the list of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweetutilities import get_geocodes\n",
    "\n",
    "bad_locations = get_geocodes(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For each tweet with a valid location, the `get_geocodes` function adds the new keys `'latitude'` and `'longitude'` to that tweet’s dictionary in the `tweets` list — these will be used to plot map markers on our interactive map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Bad Location Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{bad_locations / counts[\"locations\"]:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data\n",
    "* Before we plot the tweet locations on a map, let’s use a pandas `DataFrame` to clean the data\n",
    "* When you create a * DataFrame* from the `tweets` list, it will contain the value `NaN` for the `'latitude'` and `'longitude'` of any tweet that does not have a valid location\n",
    "* `NaN` cannot be plotted on a map, so remove any rows containing `NaN` by calling the `DataFrame`’s `dropna` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Map with Folium\n",
    "Create a folium Map on which we’ll plot the tweet locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usmap = folium.Map(location=[39.8283, -98.5795], \n",
    "    tiles='Stamen Terrain', zoom_start=5, detect_retina=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `location` keyword argument specifies a sequence containing latitude and longitude coordinates for the **map’s center point** \n",
    "    * The values in this snippet are the **geographic center of the continental United States**\n",
    "    * In many places worldwide, the term `'football'` describes the sport we call soccer in the U.S., so some of the tweets we plot may be outside the U.S\n",
    "    * You can zoom using the **+** and **–** buttons at the map’s top-left, or you can dragging the map with the mouse (that is, pan) to see anywhere in the world\n",
    "*  `zoom_start` keyword argument specifies the map’s initial zoom level, lower values show more of the world\n",
    "* `detect_retina` keyword argument enables folium to detect high-resolution screens to use higher-resolution maps from `OpenStreetMap.org`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Popup Markers for the Tweet Locations\n",
    "* Create `folium` `Popup` objects containing each tweet’s text and add them to the `Map`\n",
    "* `DataFrame` method `itertuples` creates a named tuple from each row containing properties corresponding to each `DataFrame` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in df.itertuples():\n",
    "    text = ': '.join([t.username, t.text])\n",
    "    popup = folium.Popup(text, parse_html=True)\n",
    "    marker = folium.Marker((t.latitude, t.longitude), \n",
    "                           popup=popup)\n",
    "    marker.add_to(usmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creates a string (`text`) containing the user’s `username` and tweet `text` \n",
    "* Creates a `folium` `Popup` to display the `text`\n",
    "* Creates a `folium` `Marker`\n",
    "    * tuple to specify the `Marker`’s latitude and longitude\n",
    "    * `popup` keyword argument associates the tweet’s `Popup` object with the new `Marker`\n",
    "* Calls the `Marker`’s `add_to` method to specify the `Map` that will display the `Marker`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Map\n",
    "* Call the `Map`’s `save` method to store the map in an HTML file, which you can then double-click to open in your web browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usmap.save('tweet_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "usmap # displays the map in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.15.2 Utility Functions in `tweetutilities.py` \n",
    "### `get_tweet_content` Utility Function \n",
    "* Receives a **`StreamResponse` object (`response`)** and creates a **dictionary** containing the **tweet’s `username`, `text` and `location`**\n",
    "\n",
    "```python\n",
    "def get_tweet_content(response):\n",
    "    \"\"\"Return dictionary with data from tweet.\"\"\"\n",
    "    fields = {}\n",
    "    fields['username'] = response.includes['users'][0].username\n",
    "    fields['text'] = response.data.text\n",
    "    fields['location'] = response.includes['users'][0].location\n",
    "\n",
    "    return fields\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_geocodes` Utility Function \n",
    "* Receives a list of dictionaries containing tweets and **geocodes their locations**\n",
    "* If geocoding is successful for a tweet, adds the **latitude** and **longitude** to the tweet’s **dictionary in `tweet_list`**\n",
    "* Requires class **`OpenMapQuest`** from the **geopy module**\n",
    "\n",
    "```python\n",
    "from geopy import OpenMapQuest\n",
    "```\n",
    "\n",
    "```python\n",
    "def get_geocodes(tweet_list):\n",
    "    \"\"\"Get the latitude and longitude for each tweet's location.\n",
    "    Returns the number of tweets with invalid location data.\"\"\"\n",
    "    print('Getting coordinates for tweet locations...')\n",
    "    geo = OpenMapQuest(api_key=keys.mapquest_key)  # geocoder\n",
    "    bad_locations = 0  \n",
    "\n",
    "    for tweet in tweet_list:\n",
    "        processed = False\n",
    "        delay = .1  # used if OpenMapQuest times out to delay next call\n",
    "        while not processed:\n",
    "            try:  # get coordinates for tweet['location']\n",
    "                geo_location = geo.geocode(tweet['location'])\n",
    "                processed = True\n",
    "            except:  # timed out, so wait before trying again\n",
    "                print('OpenMapQuest service timed out. Waiting.')\n",
    "                time.sleep(delay)\n",
    "                delay += .1\n",
    "\n",
    "        if geo_location:  \n",
    "            tweet['latitude'] = geo_location.latitude\n",
    "            tweet['longitude'] = geo_location.longitude\n",
    "        else:  \n",
    "            bad_locations += 1  # tweet['location'] was invalid\n",
    "    \n",
    "    print('Done geocoding')\n",
    "    return bad_locations\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_geocodes` Utility Function (cont.)\n",
    "* Creates the **`OpenMapQuest` object** we’ll use to geocode locations\n",
    "* Initializes **`bad_locations`** which we use to keep track of the number of invalid locations in the tweet objects we collected\n",
    "* Attempts to **geocode the current tweet’s location**\n",
    "* Prints a message that it’s done geocoding and returns the `bad_locations` value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.15.3 Class `LocationListener`\n",
    "```python\n",
    "# locationlistener.py\n",
    "\"\"\"Receives tweets matching a search string and stores a list of\n",
    "dictionaries containing each tweet's username/text/location.\"\"\"\n",
    "import tweepy\n",
    "from tweetutilities import get_tweet_content\n",
    "\n",
    "class LocationListener(tweepy.StreamingClient):\n",
    "    \"\"\"Handles incoming Tweet stream to get location data.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def __init__(self, bearer_token, counts_dict, \n",
    "                 tweets_list, topic, limit=10):\n",
    "        \"\"\"Configure the LocationListener.\"\"\"\n",
    "        self.tweets_list = tweets_list\n",
    "        self.counts_dict = counts_dict\n",
    "        self.topic = topic\n",
    "        self.TWEET_LIMIT = limit\n",
    "        super().__init__(bearer_token, wait_on_rate_limit=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def on_response(self, response):\n",
    "        \"\"\"Called when Twitter pushes a new tweet to you.\"\"\"\n",
    "\n",
    "        # get each tweet's username, text and location\n",
    "        tweet_data = get_tweet_content(response)  \n",
    "\n",
    "        # ignore retweets and tweets that do not contain the topic\n",
    "        if (tweet_data['text'].startswith('RT') or\n",
    "            self.topic.lower() not in tweet_data['text'].lower()):\n",
    "            return\n",
    "\n",
    "        self.counts_dict['total_tweets'] += 1 # it's an original tweet\n",
    "\n",
    "        # ignore tweets with no location \n",
    "        if not tweet_data.get('location'):  \n",
    "            return\n",
    "\n",
    "        self.counts_dict['locations'] += 1 # user account has location\n",
    "        self.tweets_list.append(tweet_data) # store the tweet\n",
    "        print(f\"{tweet_data['username']}: {tweet_data['text']}\\n\")\n",
    "        \n",
    "        # if TWEET_LIMIT is reached, terminate streaming\n",
    "        if self.counts_dict['locations'] == self.TWEET_LIMIT:\n",
    "            self.disconnect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.15.3 Class `LocationListener` (cont.)\n",
    "* `__init__` receives \n",
    "    * the `bearer_token` \n",
    "    * the number of tweets to process (`limit`)\n",
    "    * `counts` dictionary that we use to keep track of the total number of tweets processed\n",
    "    * `tweet_list` in which we store the dictionaries returned by the `get_tweet_content` utility function\n",
    "    * a string representing the topic so we can confirm that its text is contained in the tweet text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.15.3 Class `LocationListener` (cont.)\n",
    "* In method `on_response`\n",
    "   * Line 23 calls `get_tweet_content` to get each tweet’s screen name, text and location.\n",
    "    * Lines 26–28 ignore the tweet if it is a retweet or if the text does not include the topic we’re searching for\n",
    "    * Line 30 adds 1 to the value of the `'total_tweets'` key in the `counts` dictionary to track the number of original tweets\n",
    "    * Lines 33–34 ignore tweets that have no location data\n",
    "    * Line 36 adds 1 to the value of the `counts` dictionary’s `'locations'` key to indicate that we found a tweet with a location\n",
    "    * Line 37 appends the `tweet_data` dictionary to the `tweets_list`\n",
    "    * Line 38 displays the tweet’s screen name and tweet text so you can see that the app is making progress\n",
    "    * Lines 41–42 check whether the `TWEET_LIMIT` has been reached, and if so, disconnect from the stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# More Info \n",
    "* See Lesson 12 in [**Python Fundamentals LiveLessons** here on O'Reilly Online Learning](https://learning.oreilly.com/videos/python-fundamentals/9780135917411)\n",
    "* See Chapter 12 in [**Python for Programmers** on O'Reilly Online Learning](https://learning.oreilly.com/library/view/python-for-programmers/9780135231364/)\n",
    "* See Chapter 13 in [**Intro Python for Computer Science and Data Science** on O'Reilly Online Learning](https://learning.oreilly.com/library/view/intro-to-python/9780135404799/)\n",
    "* Interested in a print book? Check out:\n",
    "\n",
    "| Python for Programmers<br>(640-page professional book) | Intro to Python for Computer<br>Science and Data Science<br>(880-page college textbook)\n",
    "| :------ | :------\n",
    "| <a href=\"https://amzn.to/2VvdnxE\"><img alt=\"Python for Programmers cover\" src=\"../images/PyFPCover.png\" width=\"150\" border=\"1\"/></a> | <a href=\"https://amzn.to/2LiDCmt\"><img alt=\"Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud\" src=\"../images/IntroToPythonCover.png\" width=\"159\" border=\"1\"></a>\n",
    "\n",
    ">Please **do not** purchase both books&mdash;_Python for Programmers_ is a subset of _Intro to Python for Computer Science and Data Science_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
